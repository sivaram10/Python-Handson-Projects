{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, Conv2D\n",
    "from tensorflow.python.keras.layers import MaxPool2D, Dense, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "num_channels = 1\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 47s 859us/step - loss: 0.2945 - acc: 0.9165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x2318f2a2240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "model.add(Reshape(img_shape_full))\n",
    "model.add(Conv2D(kernel_size=5, strides=1, filters=16, padding='same', activation='relu', name='conv_layer1'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(Conv2D(kernel_size=5, strides=2, filters=32, padding='same', activation='relu', name='conv_layer2'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=data.train.images, y=data.train.labels, epochs=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 459us/step\n"
     ]
    }
   ],
   "source": [
    "result= model.evaluate(x=data.test.images, y=data.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.09760198063477873\n",
      "acc 0.9664\n",
      "acc: 96.64%\n"
     ]
    }
   ],
   "source": [
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(name, value)\n",
    "print(\"{0}: {1:.2%}\".format(model.metrics_names[1], result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 80s 1ms/step - loss: 0.2451 - acc: 0.9241\n",
      "10000/10000 [==============================] - 7s 672us/step\n",
      "loss 0.09760198063477873\n",
      "acc 0.9664\n",
      "acc: 96.64%\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(img_size_flat,))\n",
    "net = inputs\n",
    "net = Reshape(img_shape_full)(net)\n",
    "net = Conv2D(kernel_size=5, strides=1, filters=16, padding='same', activation='relu', name='conv_layer1')(net)\n",
    "net = MaxPool2D(pool_size=2, strides=2)(net)\n",
    "net = Conv2D(kernel_size=5, strides=1, filters=16, padding='same', activation='relu', name='conv_layer2')(net)\n",
    "net = MaxPool2D(pool_size=2, strides=2)(net)\n",
    "net = Flatten()(net)\n",
    "net = Dense(128, activation='relu')(net)\n",
    "net = Dense(num_classes, activation='softmax')(net)\n",
    "outputs = net\n",
    "\n",
    "model_func = Model(inputs=inputs, outputs=outputs)\n",
    "model_func.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model_func.fit(x=data.train.images, y=data.train.labels, epochs=1, batch_size=128)\n",
    "model_func.evaluate(x=data.test.images, y=data.test.labels)\n",
    "\n",
    "for name, value in zip(model_func.metrics_names, result):\n",
    "    print(name, value)\n",
    "print(\"{0}: {1:.2%}\".format(model_func.metrics_names[1], result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 600us/step\n",
      "5000/5000 [==============================] - 3s 602us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07595181209146977, 0.9782]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'model.keras'\n",
    "model_func.save(model_path)\n",
    "del model_func\n",
    "from tensorflow.python.keras.models import load_model\n",
    "model_func_saved = load_model(model_path)\n",
    "model_func_saved.evaluate(x=data.test.images, y=data.test.labels)\n",
    "model_func_saved.evaluate(x=data.validation.images, y=data.validation.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_layer1 (Conv2D)         (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 14, 14, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 108,602\n",
      "Trainable params: 108,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_func_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.14919381, -0.01331354, -0.13101117,  0.11116042,\n",
       "           0.19253737, -0.01417204,  0.08113975, -0.059536  ,\n",
       "           0.00549069, -0.11361254,  0.0861453 ,  0.11725801,\n",
       "          -0.0964651 ,  0.10747826,  0.17376587, -0.05049446]],\n",
       "\n",
       "        [[ 0.17283697,  0.1659312 , -0.01307141, -0.04050573,\n",
       "           0.16053014, -0.1095231 , -0.00414349,  0.06535481,\n",
       "           0.10398444, -0.04334639,  0.04895893,  0.01406143,\n",
       "          -0.0907459 ,  0.09475459,  0.07411278,  0.10065028]],\n",
       "\n",
       "        [[ 0.08023234,  0.148917  ,  0.08958954,  0.16025147,\n",
       "           0.135305  , -0.0843061 , -0.016828  ,  0.04589121,\n",
       "           0.10663011,  0.09767466,  0.00403546,  0.10059351,\n",
       "          -0.09096719,  0.16253401,  0.10599612,  0.10880768]],\n",
       "\n",
       "        [[-0.01583367,  0.19241506,  0.04044468,  0.0415483 ,\n",
       "           0.0922812 , -0.13344663, -0.14382344,  0.17235543,\n",
       "           0.1969471 ,  0.12597056, -0.14035459, -0.02110622,\n",
       "           0.11844183, -0.04823356,  0.02604043, -0.13452064]],\n",
       "\n",
       "        [[ 0.07594503,  0.20109315,  0.16237581,  0.16413014,\n",
       "           0.20510636, -0.1566837 ,  0.07279836,  0.06157444,\n",
       "           0.05189133,  0.00722583, -0.13482624,  0.13188654,\n",
       "           0.16246219, -0.09690806,  0.10045005, -0.1646511 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.10108161, -0.02810752, -0.0983717 , -0.00613922,\n",
       "          -0.07531273, -0.01743796,  0.15427491, -0.18440327,\n",
       "          -0.03524062, -0.17458764,  0.15255213, -0.11906071,\n",
       "          -0.12039537, -0.00404319,  0.02106104,  0.02680202]],\n",
       "\n",
       "        [[ 0.05434638,  0.02612377, -0.11723363,  0.05213575,\n",
       "          -0.05907978, -0.06813397,  0.02701412,  0.04819963,\n",
       "           0.10754211, -0.04619223, -0.0036105 ,  0.08979895,\n",
       "          -0.17924476, -0.01586316,  0.10151223,  0.16136223]],\n",
       "\n",
       "        [[ 0.09300846,  0.15851155, -0.00168896, -0.04597067,\n",
       "           0.06326159, -0.19407669, -0.09793582,  0.03600418,\n",
       "           0.04807142,  0.08169679,  0.04119639,  0.19257921,\n",
       "          -0.02103935,  0.00416556,  0.18149367,  0.05116023]],\n",
       "\n",
       "        [[-0.03207396,  0.14240555,  0.05451392,  0.14139935,\n",
       "           0.04228603, -0.19434807,  0.06159859,  0.07223713,\n",
       "           0.05636338,  0.09537815,  0.04983499, -0.01715125,\n",
       "           0.05096656,  0.06741452,  0.0263836 , -0.08671347]],\n",
       "\n",
       "        [[ 0.1612815 , -0.01614783,  0.19443314,  0.06687594,\n",
       "           0.1222344 , -0.11277875,  0.08154725,  0.06573607,\n",
       "           0.22759679, -0.05598971, -0.01703215, -0.11500111,\n",
       "          -0.00683378, -0.17005533,  0.19064678, -0.1677057 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.12104245,  0.1459063 , -0.17723273,  0.13925973,\n",
       "          -0.02342195,  0.11114714,  0.10734835, -0.11602581,\n",
       "          -0.17817353, -0.08121455,  0.20314424, -0.10324325,\n",
       "          -0.21203882, -0.02496345,  0.14925185, -0.01986903]],\n",
       "\n",
       "        [[ 0.07065508,  0.00143155, -0.16184838,  0.1045919 ,\n",
       "          -0.06468445, -0.09518695,  0.00880189,  0.1040021 ,\n",
       "          -0.1919237 ,  0.09908652,  0.06214407,  0.14445189,\n",
       "          -0.07896012,  0.19410574,  0.07985116, -0.01474175]],\n",
       "\n",
       "        [[ 0.10468042,  0.05644201, -0.07181107,  0.06356308,\n",
       "          -0.12703796,  0.0686116 ,  0.04673511,  0.04757888,\n",
       "           0.00124701,  0.15353975,  0.10458598,  0.12595966,\n",
       "           0.0210441 ,  0.11519837, -0.0767777 , -0.10284269]],\n",
       "\n",
       "        [[-0.05555283, -0.02516516,  0.18630442,  0.05464747,\n",
       "          -0.10915874,  0.04989169, -0.06964326,  0.19054776,\n",
       "           0.02084347, -0.04500344, -0.04108303,  0.15568179,\n",
       "           0.08052525, -0.08353035,  0.01032615, -0.08881496]],\n",
       "\n",
       "        [[ 0.13224322, -0.00251668,  0.17302604,  0.05426502,\n",
       "          -0.01494079,  0.11745349,  0.09884066, -0.0795562 ,\n",
       "           0.18327509, -0.02887892,  0.06128894, -0.03452436,\n",
       "           0.13342467, -0.2138487 , -0.03683367,  0.00404089]]],\n",
       "\n",
       "\n",
       "       [[[-0.09154557,  0.0386127 , -0.18466312, -0.02414478,\n",
       "          -0.1191829 ,  0.17076732,  0.02536195, -0.06091986,\n",
       "          -0.10939808,  0.083629  ,  0.11119884, -0.12894396,\n",
       "          -0.21635501,  0.14810519, -0.05026141,  0.15353148]],\n",
       "\n",
       "        [[-0.07417767,  0.0489514 , -0.01708958,  0.02445723,\n",
       "          -0.00875937, -0.02578189,  0.05558914,  0.03837806,\n",
       "          -0.12193235,  0.17992948,  0.07304665, -0.09355085,\n",
       "          -0.11912116,  0.07755934, -0.13371381,  0.09802101]],\n",
       "\n",
       "        [[-0.03057966, -0.18248813, -0.00228295, -0.12494427,\n",
       "          -0.04384726,  0.05435283, -0.03014114,  0.03557713,\n",
       "           0.08719839,  0.0382699 ,  0.20159772,  0.10537991,\n",
       "          -0.08753836,  0.08014224, -0.07702718, -0.06234151]],\n",
       "\n",
       "        [[ 0.0186442 , -0.09772538,  0.15427533, -0.1132903 ,\n",
       "          -0.15074514,  0.09872087,  0.15301782, -0.01364156,\n",
       "           0.08897352,  0.16794811,  0.0414885 , -0.0566712 ,\n",
       "           0.13159838, -0.00930436,  0.00466308,  0.10790525]],\n",
       "\n",
       "        [[-0.07601719,  0.05093708,  0.15169914, -0.07553159,\n",
       "          -0.13993928,  0.14837211, -0.02848952,  0.02600572,\n",
       "          -0.00094659, -0.06814583,  0.11558115,  0.02976795,\n",
       "           0.17182381, -0.05137627, -0.11779811, -0.04644542]]],\n",
       "\n",
       "\n",
       "       [[[-0.0799315 , -0.16544333, -0.04922797, -0.24117698,\n",
       "          -0.11495993,  0.11756752,  0.10363972, -0.03190308,\n",
       "          -0.00967167,  0.0392938 ,  0.08013166, -0.04078473,\n",
       "          -0.08252802,  0.16302653, -0.11417698,  0.03253955]],\n",
       "\n",
       "        [[-0.03926658, -0.19401853,  0.01593088, -0.24034272,\n",
       "          -0.10018021,  0.06538008,  0.03760583,  0.10443226,\n",
       "          -0.13223064,  0.15956317, -0.12086485,  0.0191306 ,\n",
       "          -0.12250404, -0.01603012, -0.04507353,  0.12480883]],\n",
       "\n",
       "        [[-0.03329509, -0.09627401, -0.04047685, -0.0719427 ,\n",
       "          -0.0916473 ,  0.14301348,  0.11512026,  0.11875538,\n",
       "           0.00385121,  0.1077147 , -0.03322913,  0.10966923,\n",
       "          -0.04572401,  0.05904007, -0.23175263,  0.06118498]],\n",
       "\n",
       "        [[-0.14238308, -0.15866484,  0.09067473, -0.17155668,\n",
       "           0.0214934 ,  0.17975649,  0.15282983,  0.0363409 ,\n",
       "          -0.05027543, -0.01895137, -0.02278727,  0.0867369 ,\n",
       "          -0.00412499,  0.03250414, -0.07305101,  0.13041963]],\n",
       "\n",
       "        [[-0.09266161, -0.05127953,  0.0513522 , -0.12504259,\n",
       "           0.03593836,  0.13470085, -0.07726535,  0.08654031,\n",
       "           0.09522745, -0.11084474, -0.01086712, -0.10571282,\n",
       "           0.1687905 , -0.01370419, -0.17832884,  0.03864987]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_func_saved.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1, 16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_func_saved.layers[2].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training on more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 82s 1ms/step - loss: 0.2179 - acc: 0.9367\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 87s 2ms/step - loss: 0.0581 - acc: 0.9813\n",
      "10000/10000 [==============================] - 7s 741us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04566507011021022, 0.9833]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "model1.add(Reshape(img_shape_full))\n",
    "model1.add(Conv2D(kernel_size=5, padding='same', strides=1, filters=16, activation='relu', name='conv_layer1'))\n",
    "model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "model1.add(Conv2D(kernel_size=5, strides=1, filters=32, padding='same', activation='relu', name='conv_layer2'))\n",
    "model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "model1.fit(x=data.train.images, y= data.train.labels, epochs=2, batch_size=128)\n",
    "model1.evaluate(x=data.test.images, y=data.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using sigmoid instead on relu activaion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 90s 2ms/step - loss: 1.2266 - acc: 0.5893\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 85s 2ms/step - loss: 0.2470 - acc: 0.9267\n",
      "10000/10000 [==============================] - 7s 713us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1597835160881281, 0.9526]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "model1.add(Reshape(img_shape_full))\n",
    "model1.add(Conv2D(kernel_size=5, padding='same', strides=1, filters=16, activation='sigmoid', name='conv_layer1'))\n",
    "model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "model1.add(Conv2D(kernel_size=5, strides=1, filters=32, padding='same', activation='sigmoid', name='conv_layer2'))\n",
    "model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation='sigmoid'))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "model1.fit(x=data.train.images, y= data.train.labels, epochs=2, batch_size=128)\n",
    "model1.evaluate(x=data.test.images, y=data.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using elu activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 88s 2ms/step - loss: 0.1906 - acc: 0.9439\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 87s 2ms/step - loss: 0.0531 - acc: 0.9833\n",
      "10000/10000 [==============================] - 7s 741us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044801207398506813, 0.9842]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "model1.add(Reshape(img_shape_full))\n",
    "model1.add(Conv2D(kernel_size=5, padding='same', strides=1, filters=16, activation='elu', name='conv_layer1'))\n",
    "model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "model1.add(Conv2D(kernel_size=5, strides=1, filters=32, padding='same', activation='elu', name='conv_layer2'))\n",
    "model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128, activation='elu'))\n",
    "model1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "model1.fit(x=data.train.images, y= data.train.labels, epochs=2, batch_size=128)\n",
    "model1.evaluate(x=data.test.images, y=data.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Change activation function with single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 87s 2ms/step - loss: 0.1927 - acc: 0.9425\n",
      "10000/10000 [==============================] - 8s 762us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05806006715670228, 0.9802]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "\n",
    "def conv_model(activation='sigmoid'):\n",
    "    model1 = Sequential()\n",
    "    model1.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "    model1.add(Reshape(img_shape_full))\n",
    "    model1.add(Conv2D(kernel_size=5, padding='same', strides=1, filters=16, activation=activation, name='conv_layer1'))\n",
    "    model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "    model1.add(Conv2D(kernel_size=5, strides=1, filters=32, padding='same', activation=activation, name='conv_layer2'))\n",
    "    model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(128, activation=activation))\n",
    "    model1.add(Dense(num_classes, activation='softmax'))\n",
    "    return model1\n",
    "\n",
    "model_func = conv_model(activation='elu')\n",
    "optimizer = Adam(lr=0.001)\n",
    "model_func.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "model_func.fit(x=data.train.images, y= data.train.labels, epochs=1, batch_size=128)\n",
    "model_func.evaluate(x=data.test.images, y=data.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Change stride in conv layer and see the difference in accuracy and running times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 16s 283us/step - loss: 0.3514 - acc: 0.8997\n",
      "10000/10000 [==============================] - 2s 220us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10827499214857816, 0.9661]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "\n",
    "def conv_model(activation='sigmoid'):\n",
    "    model1 = Sequential()\n",
    "    model1.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "    model1.add(Reshape(img_shape_full))\n",
    "    model1.add(Conv2D(kernel_size=5, padding='same', strides=2, filters=16, activation=activation, name='conv_layer1'))\n",
    "    model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "    model1.add(Conv2D(kernel_size=5, strides=2, filters=32, padding='same', activation=activation, name='conv_layer2'))\n",
    "    model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(128, activation=activation))\n",
    "    model1.add(Dense(num_classes, activation='softmax'))\n",
    "    return model1\n",
    "\n",
    "model_func = conv_model(activation='elu')\n",
    "optimizer = Adam(lr=0.001)\n",
    "model_func.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "model_func.fit(x=data.train.images, y= data.train.labels, epochs=1, batch_size=128)\n",
    "model_func.evaluate(x=data.test.images, y=data.test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Add more conv layers and see the difference in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "55000/55000 [==============================] - 117s 2ms/step - loss: 0.1905 - acc: 0.9418\n",
      "10000/10000 [==============================] - 10s 992us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05552197875850834, 0.9819]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "img_shape_full = (img_size, img_size, 1)\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "\n",
    "def conv_model(activation='sigmoid'):\n",
    "    model1 = Sequential()\n",
    "    model1.add(InputLayer(input_shape=(img_size_flat,)))\n",
    "    model1.add(Reshape(img_shape_full))\n",
    "    model1.add(Conv2D(kernel_size=5, padding='same', strides=1, filters=16, activation=activation, name='conv_layer1'))\n",
    "    model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "    model1.add(Conv2D(kernel_size=5, strides=1, filters=32, padding='same', activation=activation, name='conv_layer2'))\n",
    "    model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "    model1.add(Conv2D(kernel_size=5, strides=1, filters=64, padding='same', activation=activation, name='conv_layer3'))\n",
    "    model1.add(MaxPool2D(strides=2, pool_size=2))\n",
    "    model1.add(Flatten())\n",
    "    model1.add(Dense(128, activation=activation))\n",
    "    model1.add(Dense(num_classes, activation='softmax'))\n",
    "    return model1\n",
    "\n",
    "model_func = conv_model(activation='elu')\n",
    "optimizer = Adam(lr=0.001)\n",
    "model_func.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics =['accuracy'])\n",
    "model_func.fit(x=data.train.images, y= data.train.labels, epochs=1, batch_size=128)\n",
    "model_func.evaluate(x=data.test.images, y=data.test.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
